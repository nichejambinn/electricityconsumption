# name the components
agent-date.sources = source-spool
agent-date.sinks = sink-hdfs-ym sink-hdfs-ymd
agent-date.channels = channel-hdfs-ym channel-hdfs-ymd

# describe and configure the source
agent-date.sources.source-spool.type = spooldir
agent-date.sources.source-spool.spoolDir = /home/hadoopuser/phase2/flume/spooldir

# define interceptor to extract the date
agent-date.sources.source-spool.interceptors = id
agent-date.sources.source-spool.interceptors.id.type = org.apache.flume.interceptor.RegexExtractorInterceptorMillisSerializer
agent-date.sources.source-spool.interceptors.id.regex = (\d\d\d\d-\d\d-\d\d\s+\d\d:\d\d:\d\d)
agent-date.sources.source-spool.interceptors.id.serializers = s1
agent-date.sources.source-spool.interceptors.id.serializers.s1.name = timestamp
agent-date.sources.source-spool.interceptors.id.serializers.s1.pattern = yyyy-MM-dd HH:mm:ss

# define the sinks - hdfs sink picks up timestamp header for path
agent-date.sinks.sink-hdfs-ym.type = hdfs
agent-date.sinks.sink-hdfs-ym.hdfs.path = /ecoFlume/good/%Y/%m
agent-flag.sinks.sink-hdfs-ym.hdfs.fileSuffix = .log
agent-flag.sinks.sink-hdfs-ym.hdfs.inUsePrefix = _
agent-flag.sinks.sink-hdfs.hdfs.fileType = DataStream

agent-date.sinks.sink-hdfs-ymd.type = hdfs
agent-date.sinks.sink-hdfs-ymd.hdfs.path = /ecoFlume/good/%Y/%m/%d
agent-flag.sinks.sink-hdfs-ymd.hdfs.fileSuffix = .log
agent-flag.sinks.sink-hdfs-ymd.hdfs.inUsePrefix = _
agent-flag.sinks.sink-hdfs.hdfs.fileType = DataStream

# hdfs time-saving options

# use a channel to buffer events
agent-date.channels.channel-hdfs-ym.type = memory
agent-date.channels.channel-hdfs-ymd.type = memory

# bind the source and sink to the channel
agent-date.sources.source-spool.channels = channel-hdfs-ym channel-hdfs-ymd
agent-date.sinks.sink-hdfs-ym.channel = channel-hdfs-ym
agent-date.sinks.sink-hdfs-ymd.channel = channel-hdfs-ymd

# flume-ng agent --conf-file $FLUME_HOME/conf/replicate-by-date.conf --name agent-date --conf $FLUME_HOME/conf -Dflume.root.logger=INFO,console